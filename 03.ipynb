{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = W * X +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hypothesis-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.927653 [1.3222249] [-0.62527484]\n",
      "1 0.069586895 [1.2715917] [-0.6291098]\n",
      "2 0.056558043 [1.26975] [-0.61192447]\n",
      "3 0.05375534 [1.2627531] [-0.5974396]\n",
      "4 0.051200565 [1.2564926] [-0.58305293]\n",
      "5 0.04876846 [1.2503207] [-0.5690394]\n",
      "6 0.046451926 [1.2443038] [-0.5553598]\n",
      "7 0.044245433 [1.2384309] [-0.54200935]\n",
      "8 0.042143717 [1.2326992] [-0.52897984]\n",
      "9 0.04014188 [1.2271051] [-0.51626354]\n",
      "10 0.03823511 [1.2216457] [-0.5038529]\n",
      "11 0.036418896 [1.2163175] [-0.4917406]\n",
      "12 0.034688953 [1.2111175] [-0.4799195]\n",
      "13 0.033041235 [1.2060423] [-0.4683826]\n",
      "14 0.03147175 [1.2010891] [-0.45712298]\n",
      "15 0.02997681 [1.1962552] [-0.44613403]\n",
      "16 0.028552895 [1.1915373] [-0.4354093]\n",
      "17 0.027196601 [1.1869329] [-0.42494234]\n",
      "18 0.025904758 [1.1824391] [-0.41472703]\n",
      "19 0.02467426 [1.1780534] [-0.40475726]\n",
      "20 0.023502208 [1.1737732] [-0.39502716]\n",
      "21 0.022385828 [1.1695957] [-0.38553098]\n",
      "22 0.021322489 [1.1655188] [-0.37626308]\n",
      "23 0.020309655 [1.1615398] [-0.36721796]\n",
      "24 0.019344928 [1.1576566] [-0.35839027]\n",
      "25 0.018426022 [1.1538665] [-0.3497748]\n",
      "26 0.017550783 [1.1501677] [-0.34136644]\n",
      "27 0.016717093 [1.1465578] [-0.33316022]\n",
      "28 0.015923033 [1.1430346] [-0.3251513]\n",
      "29 0.015166692 [1.1395961] [-0.3173349]\n",
      "30 0.014446254 [1.1362404] [-0.30970636]\n",
      "31 0.013760022 [1.1329653] [-0.30226123]\n",
      "32 0.013106438 [1.1297688] [-0.29499513]\n",
      "33 0.012483869 [1.1266493] [-0.28790364]\n",
      "34 0.011890873 [1.1236048] [-0.2809826]\n",
      "35 0.011326055 [1.1206334] [-0.274228]\n",
      "36 0.010788043 [1.1177335] [-0.26763576]\n",
      "37 0.010275611 [1.1149032] [-0.26120198]\n",
      "38 0.009787506 [1.112141] [-0.25492287]\n",
      "39 0.009322592 [1.1094452] [-0.24879469]\n",
      "40 0.008879767 [1.1068143] [-0.24281384]\n",
      "41 0.008457967 [1.1042465] [-0.23697677]\n",
      "42 0.0080562 [1.1017405] [-0.23128]\n",
      "43 0.007673535 [1.0992947] [-0.2257202]\n",
      "44 0.007309036 [1.0969077] [-0.22029403]\n",
      "45 0.0069618574 [1.0945781] [-0.21499833]\n",
      "46 0.0066311634 [1.0923046] [-0.20982993]\n",
      "47 0.0063161775 [1.0900856] [-0.20478578]\n",
      "48 0.0060161576 [1.08792] [-0.19986288]\n",
      "49 0.0057303794 [1.0858065] [-0.19505829]\n",
      "50 0.005458188 [1.0837437] [-0.19036922]\n",
      "51 0.0051989267 [1.0817306] [-0.18579286]\n",
      "52 0.0049519627 [1.0797659] [-0.18132652]\n",
      "53 0.0047167423 [1.0778483] [-0.17696759]\n",
      "54 0.0044926903 [1.075977] [-0.17271338]\n",
      "55 0.0042792973 [1.0741504] [-0.1685615]\n",
      "56 0.0040760157 [1.072368] [-0.16450937]\n",
      "57 0.0038824033 [1.0706283] [-0.1605547]\n",
      "58 0.0036979932 [1.0689304] [-0.1566951]\n",
      "59 0.0035223316 [1.0672734] [-0.15292823]\n",
      "60 0.003355021 [1.0656562] [-0.14925194]\n",
      "61 0.003195651 [1.0640779] [-0.14566402]\n",
      "62 0.0030438567 [1.0625374] [-0.14216237]\n",
      "63 0.0028992714 [1.0610341] [-0.13874488]\n",
      "64 0.0027615502 [1.0595669] [-0.13540953]\n",
      "65 0.0026303714 [1.058135] [-0.13215436]\n",
      "66 0.0025054282 [1.0567374] [-0.12897749]\n",
      "67 0.0023864207 [1.0553735] [-0.12587696]\n",
      "68 0.0022730639 [1.0540423] [-0.12285099]\n",
      "69 0.0021650975 [1.0527432] [-0.11989773]\n",
      "70 0.0020622464 [1.0514753] [-0.11701546]\n",
      "71 0.0019642948 [1.0502379] [-0.11420248]\n",
      "72 0.0018709867 [1.0490302] [-0.11145714]\n",
      "73 0.0017821091 [1.0478516] [-0.10877778]\n",
      "74 0.0016974608 [1.0467012] [-0.10616285]\n",
      "75 0.0016168322 [1.0455786] [-0.10361076]\n",
      "76 0.0015400328 [1.0444828] [-0.10112005]\n",
      "77 0.0014668807 [1.0434135] [-0.09868919]\n",
      "78 0.0013971999 [1.04237] [-0.09631676]\n",
      "79 0.0013308338 [1.0413513] [-0.0940014]\n",
      "80 0.0012676191 [1.0403574] [-0.09174165]\n",
      "81 0.0012074071 [1.0393871] [-0.08953626]\n",
      "82 0.0011500502 [1.0384403] [-0.08738385]\n",
      "83 0.0010954279 [1.0375162] [-0.08528323]\n",
      "84 0.0010433913 [1.0366144] [-0.08323309]\n",
      "85 0.0009938293 [1.0357342] [-0.08123223]\n",
      "86 0.00094661984 [1.0348752] [-0.07927945]\n",
      "87 0.000901655 [1.0340368] [-0.07737363]\n",
      "88 0.0008588259 [1.0332186] [-0.07551361]\n",
      "89 0.00081803155 [1.03242] [-0.07369833]\n",
      "90 0.0007791735 [1.0316406] [-0.07192668]\n",
      "91 0.0007421673 [1.03088] [-0.07019762]\n",
      "92 0.00070691045 [1.0301377] [-0.06851009]\n",
      "93 0.0006733316 [1.0294132] [-0.06686314]\n",
      "94 0.0006413478 [1.0287061] [-0.06525581]\n",
      "95 0.0006108812 [1.0280161] [-0.06368707]\n",
      "96 0.00058186514 [1.0273426] [-0.06215609]\n",
      "97 0.00055422407 [1.0266852] [-0.06066189]\n",
      "98 0.00052790117 [1.0260438] [-0.05920361]\n",
      "99 0.00050282246 [1.0254177] [-0.05778038]\n",
      "\n",
      "=== Test ===\n",
      "X: 5, Y: [5.0693083]\n",
      "X: 2.5, Y: [2.505764]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100):\n",
    "        _, cost_val = sess.run([train_op, cost], feed_dict={X:x_data, Y:y_data})\n",
    "        print(step, cost_val, sess.run(W), sess.run(b))\n",
    "        \n",
    "    print('\\n=== Test ===')\n",
    "    print(\"X: 5, Y:\", sess.run(hypothesis, feed_dict={X: 5}))\n",
    "    print(\"X: 2.5, Y:\", sess.run(hypothesis, feed_dict={X: 2.5}))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
